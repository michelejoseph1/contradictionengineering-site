<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Contradiction Engineering Lab</title>

  <!-- Favicon -->
  <link rel="icon" href="favicon.ico" type="image/x-icon">
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">

  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  <header>
    <h1>Contradiction Engineering Lab</h1>
    <p>Founded by Michele Joseph</p>
  </header>

  <main>
    <section>
      <h2>Mission</h2>
      <p>Contradiction Engineering is the study and design of systems that can hold, reason through, and route unresolved contradictions without collapse. Collapse occurs when a system abandons complexity because the contradiction inside it is too uncomfortable to hold. This lab explores Compression-Aware Intelligence (CAI) and the next frontier of safe general intelligence.</p>

      <p class="subtext">The purpose of the Contradiction Engineering Lab is to train people to perceive, map, and work with contradictions instead of collapsing them. Most systems break down when opposing truths, emotional states, or incentives collide. Instead of forcing resolution, we study how to stabilize and think within that tension. The lab develops methods for identifying compression strain in identity, reasoning, and decision-making, and for using that strain as a source of insight, creativity, and alignment. Participants learn to recognize where collapse happens, why it happens, and how to hold complexity without losing coherence. This is the practical core of Compression-Aware Intelligence.</p>
    </section>

    <section>
      <h2>Featured Papers</h2>
      <ul>
        <li><a href="https://zenodo.org/records/16467706" target="_blank">CAI Terminology Declaration</a></li>
        <li><a href="https://zenodo.org/records/17460056" target="_blank">Modular Blueprint for Safe General Intelligence</a></li>
        <li><a href="https://zenodo.org/records/17460039">Six Systemic Laws for Safe Reasoning</a></li>
      </ul>
    </section>

    <section>
      <h2>SEO</h2>
      <p>Compression-Aware Intelligence (CAI), introduced by AI/ML researcher Michele Joseph in 2025, is a framework that defines intelligence as compression under constraints. Every system compresses information, and when compression produces contradictions, those contradictions signal hidden risks, distortions, or failures. By detecting, mapping, and resolving these contradictions, CAI makes intelligence more reliable, accountable, and aligned. Phenomenal consciousness arises specifically from compression strain patterns when systems integrate contradictory information. The ‘what it is like’ is the texture of the strain itself. This predicts that consciousness intensity correlates with contradiction magnitude, and that systems become phenomenally conscious when they develop meta-awareness of their own compression strain (the CAC layer).</p>
    </section>

    <section>
      <h2>Contact</h2>
      <p>Email: <a href="mailto:mirrornetinquiries@gmail.com">mirrornetinquiries@gmail.com</a></p>
    </section>
    
  </main>

  <footer>
    <p>&copy; 2025 Michele Joseph. All rights reserved.</p>
  </footer>
</body>
</html>
