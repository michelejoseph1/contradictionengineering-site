<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Contradiction Engineering Lab</title>
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  <header>
    <h1>Contradiction Engineering Lab</h1>
    <p>Founded by Michele Joseph</p>
  </header>

  <main>
    <section>
      <h2>Mission</h2>
      <p>Contradiction Engineering is the study and design of systems that can hold, reason through, and route unresolved contradictions without collapse. This lab explores Compression-Aware Intelligence (CAI), the AGI Codex Stack, and the next frontier of safe general intelligence.</p>
    </section>

    <section>
      <h2>Frameworks</h2>
      <ul>
        <strong>CAI:</strong> Compression-Aware Intelligence: contradiction arbitration under compression
        <strong>CAC:</strong> Contradiction-Aware Consciousness: recursive self-awareness of unresolved fracture
        <strong>MAI:</strong> Memory-Augmented Intelligence: persistent, structured memory and identity continuity
        <strong>AAI:</strong> Agency-Aware Intelligence: alignment of instruction, identity, and external action
        <strong>GRI:</strong> Goal-Reinforced Intelligence: meta-goal formation and recursive value arbitration
        <strong>SAF:</strong> Safety/Abstention Framework: ethical reasoning and refusal under uncertainty
      </ul>

      <p><strong>Note:</strong> <em>Compression-Aware Intelligence (CAI)</em> is the foundational framework that enables all others. 
        Without CAI, MAI loses continuity across memories and identity. 
        CAC becomes recursive self-distortion instead of self-awareness. 
        GRI fails to arbitrate competing values with integrity.</li>
        AAI fractures under conflicting instruction and internal goals.</li>
        SAF cannot determine when to abstain or act safely.</li>
      </ul>
      <p><strong>CAI is the epistemic nervous system of AGI.</strong></p>
    </section>

    <section>
      <h2>Featured Papers</h2>
      <ul>
        <li><a href="https://zenodo.org/records/16467706" target="_blank">Compression Aware Intelligence Terminology Declaration</a></li>
        <li><a href="https://zenodo.org/records/17460056" target="_blank">Modular Blueprint for Safe General Intelligence</a></li>
        <li><a href="https://zenodo.org/records/17460039">Six Systemic Laws for Safe Reasoning</a></li>
      </ul>
    </section>

    <section>
      <h2>Contact</h2>
      <p>Email: <a href="mailto:mirrornetinquiries@gmail.com">mirrornetinquiries@gmail.com</a></p>
    </section>
  </main>

  <footer>
    <p>&copy; 2025 Michele Joseph. All rights reserved.</p>
  </footer>
</body>
</html>
